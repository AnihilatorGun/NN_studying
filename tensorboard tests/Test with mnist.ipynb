{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "751e3994-fd8a-43c5-a671-bb9f18d11036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple, List, Type, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf4cbdfc-f877-471f-85fc-3bdd8ed27bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a47643a-eeb3-4804-8295-d4af2c5e4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop(size=(28, 28), scale=(0.5, 1.0), ratio=(0.9, 1.1)),\n",
    "                                            torchvision.transforms.RandomRotation(degrees=15),\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.15,), (0.31,))])\n",
    "\n",
    "test_aug = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                           torchvision.transforms.Normalize((0.15,), (0.31,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc74f1b-1b04-408a-bc20-df76be885682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce42be4b6471429697bc525c489921a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c858d8e82d4899b4fc896cba78674f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1148e2471c46f0943e0d0fa1bcbc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d473178a459490290dad27da3424c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='', download=True, train=True, transform=train_aug)\n",
    "test_data = torchvision.datasets.MNIST(root='', download=True, train=False, transform=test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70465310-786a-446e-8b65-eac8f6ece937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, output_sizes='default', activation=torch.nn.ReLU):\n",
    "        super(Network, self).__init__()\n",
    "        if output_sizes == 'default':\n",
    "            self.output_sizes = [512, 128, 64, 10]\n",
    "        else:\n",
    "            self.output_sizes = output_sizes\n",
    "        self.act = activation\n",
    "        \n",
    "        self._make_net()\n",
    "        \n",
    "    def _make_net(self):\n",
    "        blocks = []\n",
    "        prev_size = 28*28\n",
    "        \n",
    "        blocks.append(torch.nn.Flatten())\n",
    "        \n",
    "        for size in self.output_sizes:\n",
    "            blocks.append(torch.nn.Linear(in_features=prev_size, out_features=size))\n",
    "            blocks.append(self.act())\n",
    "            \n",
    "            prev_size = size\n",
    "            \n",
    "        self.net = torch.nn.Sequential(*blocks[:-1])\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        return self.net(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0845e74-fe19-4bc5-8877-20a263a52144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer,\n",
    "                       train_dataloader: torch.utils.data.DataLoader,\n",
    "                       loss_fn: torch.nn.Module,\n",
    "                       tb_writer: SummaryWriter,\n",
    "                       epoch: int):\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    \n",
    "    with tqdm(total=len(train_dataloader)) as pbar:\n",
    "        for step, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            prediction = model(X)\n",
    "            loss = loss_fn(prediction, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_value += loss.item()\n",
    "            \n",
    "            pbar.update()\n",
    "            pbar.set_postfix({'loss - ':loss_value})\n",
    "            \n",
    "    for tag, param in model.named_parameters():\n",
    "        tb_writer.add_histogram('grad/%s'%tag, param.grad.data.cpu().numpy(), epoch)\n",
    "        tb_writer.add_histogram('weight/%s'%tag, param.data.cpu().numpy(), epoch)\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63bdce71-82f2-4d14-91c5-c156f869720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          val_dataloader: torch.utils.data.DataLoader):\n",
    "    model.eval()\n",
    "    size = len(val_dataloader.dataset)\n",
    "    num_butches = len(val_dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in val_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_butches\n",
    "    correct /= size\n",
    "    \n",
    "    return {'loss': test_loss, 'accuracy' : correct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f48a5703-4fc0-425a-a4ad-acf98ba3219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
    "                optimizer_params: Dict = {},\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                batch_size = 64,\n",
    "                max_epochs = 100,\n",
    "                early_stopping_patience = 10,\n",
    "                is_save = False):\n",
    "\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_params)   \n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    tb_writer = SummaryWriter()\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = 0\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        train_loss_for_epoch = train_single_epoch(model, optimizer, train_loader, loss_function, tb_writer, epoch)\n",
    "        loss_history.append(train_loss_for_epoch)\n",
    "        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n",
    "        \n",
    "        tb_writer.add_scalar('train_loss', train_loss_for_epoch, epoch)\n",
    "        tb_writer.add_scalar('val_loss', val_metrics['loss'], epoch)\n",
    "        tb_writer.add_scalar('val_accuracy', val_metrics['accuracy'], epoch)\n",
    "        \n",
    "        print(f'Validation metrics: \\n{val_metrics}')\n",
    "\n",
    "        lr_scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        if is_save and (best_val_loss is None or best_val_loss > val_metrics['loss']):\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, './best_model.pth')\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6150cf27-4f5f-40f4-9b2a-69b35c99793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (net): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of trainable parameters : 476490\n"
     ]
    }
   ],
   "source": [
    "net = Network().to(device)\n",
    "print(net)\n",
    "print('Total number of trainable parameters : {}'.format(sum(parameter.numel() for parameter in net.parameters() if parameter.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45200600-2bc6-4da5-b0c4-0312595cecea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85678a6c4f4d4c00ab1d030c965d8ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e01c30b462542a9841742d427000dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.1472013020104948, 'accuracy': 0.9546}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2519484ab144c2b2e37a464acef4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.10115171148245976, 'accuracy': 0.9672}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc250fa5c4a549f9a09ff570b4b33462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.08670728280083692, 'accuracy': 0.9706}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982c0412059e4a5a99179aa0355bb1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.0856634212804626, 'accuracy': 0.9726}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2632170de10f4262827d89defdd85a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.06362745913255746, 'accuracy': 0.9796}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d934247f86743ae8709ae65a3a84b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.06373749558063473, 'accuracy': 0.9778}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882f3f4d21d147e1b399cd357929b97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.06722666027734744, 'accuracy': 0.9777}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2968c0982ed47bca6138d39a99950e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.07851365542671032, 'accuracy': 0.9744}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c806bdb6e5cc4b33974e373d5d0a0db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.06860259617678821, 'accuracy': 0.9797}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc49df81000c4cc2aae9fd79921fcff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.05766284259300898, 'accuracy': 0.9817}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[466.558920674026,\n",
       " 217.4366431310773,\n",
       " 176.32391147129238,\n",
       " 158.9316128231585,\n",
       " 142.55198414996266,\n",
       " 133.33365505374968,\n",
       " 128.31265699584037,\n",
       " 120.78331385320053,\n",
       " 117.179966757074,\n",
       " 113.21249551605433]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(net,\n",
    "           train_data,\n",
    "           test_data,\n",
    "           max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3e985-7bb0-4500-b916-bd498706a073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
