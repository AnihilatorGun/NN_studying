{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OQPcJpwUAGms"},"outputs":[],"source":["import torch\n","import torchvision\n","from torch.nn import ReLU, Conv2d, BatchNorm2d, Sequential, AdaptiveAvgPool2d, Linear, MaxPool2d, Flatten, CrossEntropyLoss\n","from typing import Tuple, List, Type, Dict, Any\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BYDwl5wna0d"},"outputs":[],"source":["class SphericalClassifier(torch.nn.Linear):\n","    \"\"\"\n","    Last layer of network, solves metric learning task via classification\n","    forward-call takes data and targets and returns logits.\n","    \"\"\"\n","    def __init__(self, in_features, out_features, scale = 64, margins=(1.0, 0, 0)):\n","        super(SphericalClassifier, self).__init__(in_features, out_features, bias=False)\n","        self._scale = scale\n","        self._margins = margins\n","\n","    def __logits_calculator(self, cosines, target):\n","        m1, m2, m3 = self._margins\n","        one_hot = torch.zeros_like(cosines)\n","        one_hot.scatter_(1, target.view(-1, 1).long(), 1)\n","\n","        req_cosines = torch.sum(one_hot * cosines, dim=1, keepdim=True)\n","        req_cosines = torch.cos(m2 + m1*torch.arccos(req_cosines))\n","        logits = self._scale * (cosines.scatter(dim=1,\n","                                               index=target.view(-1, 1).long(),\n","                                               src=req_cosines) - one_hot * m3)\n","        \n","        return logits\n"," \n","    def calculate_cosines(self, data):\n","        return torch.nn.functional.linear(torch.nn.functional.normalize(data),\n","                                  torch.nn.functional.normalize(self.weight))\n","        \n","    def forward(self, data, target):\n","        cosines = self.calculate_cosines(data)\n","        logits = self.__logits_calculator(cosines, target)\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wnv9H8Rd8Vji"},"outputs":[],"source":["class Embedder(torch.nn.Module):\n","    \"\"\"\n","    Main part on network, maps images to embeddings, based on resnets\n","    Arg:\n","    embedding_dim -- size of embedding space\n","\n","    cut_fc -- if False, after convolutions fully-conected layer will be applied,\n","    if False, there will be no fully-connected layer and very last\n","    convolutional block(resblock or bottleneck) will be replaced with usual conv\n","    with out_channels=embedding_dim\n","\n","    reference_resnet -- describe the base model which will be modified\n","\n","    after_relu -- if True, applies ReLU activation in the vety end.\n","    \"\"\"\n","    __references = {'18' : (torchvision.models.resnet18, torchvision.models.ResNet18_Weights.DEFAULT, 1, 512),\n","                    '34' : (torchvision.models.resnet34, torchvision.models.ResNet34_Weights.DEFAULT, 2, 512),\n","                    '50' : (torchvision.models.resnet50, torchvision.models.ResNet50_Weights.DEFAULT, 2, 2048)}\n","\n","    def __init__(self, embedding_dim = 128, cut_fc = False, reference_resnet = '18', after_relu=False):\n","        super(Embedder, self).__init__()\n","        self.cut_fc = cut_fc\n","        self.__embedding_dim = embedding_dim\n","        self.__reference_resnet = reference_resnet\n","        self.__after_relu = ReLU() if after_relu else None\n","        self.__build_resnet()\n","        \n","    def __build_resnet(self):\n","        ref_class, weights, layer, in_channels = Embedder.__references[self.__reference_resnet]\n","\n","        self.__inner = ref_class(weights=weights)\n","        if not self.cut_fc:\n","            self.__inner.fc = Linear(in_channels, self.__embedding_dim)\n","        else:\n","            self.__inner.layer4[layer] = Conv2d(in_channels, self.__embedding_dim, kernel_size=3, padding=1, stride=1, bias=False)\n","            self.__flatten = torch.nn.Flatten()\n","            del(self.__inner.fc)\n","\n","    @property\n","    def embedding_dim(self):\n","        return self.__embedding_dim\n","    \n","    def forward(self, x):\n","        if not self.cut_fc:\n","            if self.__after_relu:\n","                return self.__after_relu(self.__inner(x))\n","            else:\n","                return self.__inner(x)\n","        else:\n","            x = self.__inner.relu(self.__inner.bn1(self.__inner.conv1(x)))\n","            x = self.__inner.maxpool(x)\n","            x = self.__inner.layer1(x)\n","            x = self.__inner.layer2(x)\n","            x = self.__inner.layer3(x)\n","            x = self.__inner.layer4(x)\n","            x = self.__inner.avgpool(x)\n","            x = self.__flatten(x)\n","            if self.__after_relu:\n","                return self.__after_relu(x)\n","            else:\n","                return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nPqEBQUBDq00"},"outputs":[],"source":["class UnitedModel(torch.nn.Module):\n","    def __init__(self,\n","                 out_features_classifier,\n","                 scale=64,\n","                 margins=(1.0, 0, 0),\n","                 embedding_dim=128,\n","                 cut_fc=False,\n","                 reference_resnet='18',\n","                 after_relu=False):\n","        super(UnitedModel, self).__init__()\n","        self.embedder = Embedder(embedding_dim, cut_fc, reference_resnet, after_relu)\n","        self.classifier = SphericalClassifier(embedding_dim, out_features_classifier, scale, margins)\n","        \n","    def forward(self, imgs, labels):\n","        embeddings = self.embedder(imgs)\n","        logits = self.classifier(embeddings, labels)\n","        return logits"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}