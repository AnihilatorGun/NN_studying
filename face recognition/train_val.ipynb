{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LGeRrOhu2rXX","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1678365252512,"user_tz":-180,"elapsed":4527,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}},"outputId":"f53cc905-b887-468c-b31b-8c1fb962dcb5"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-224321c3a266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0madabelief_pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m  \u001b[0;31m# sometimes it is required to clean GPU memory in that way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adabelief_pytorch'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np  # Load required libs\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","from tqdm.notebook import tqdm\n","import os\n","import zipfile\n","import copy\n","import time\n","import sys\n","from typing import Tuple, List, Type, Dict, Any\n","import adabelief_pytorch\n","import gc  # sometimes it is required to clean GPU memory in that way"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aQRIWg_7pYx","executionInfo":{"status":"aborted","timestamp":1678365252514,"user_tz":-180,"elapsed":13,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}}},"outputs":[],"source":["def clear_cuda():\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aNNeXlRB9ou","executionInfo":{"status":"aborted","timestamp":1678365252517,"user_tz":-180,"elapsed":16,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}}},"outputs":[],"source":["def train_data_processing_celeba(data, model, loss_fn):\n","    imgs, labels = data\n","    embeddings = model.embedder(imgs)\n","    logits = model.classifier(embeddings, labels)\n","    \n","    loss = loss_fn(logits, labels)\n","    return loss\n","\n","def val_data_processing_celeba(data, model, loss_fn):\n","    imgs, labels = data\n","    embeddings = model.embedder(imgs)\n","    pred = model.classifier.calculate_cosines(embeddings)\n","    \n","    correct = (pred.argmax(1) == labels).type(torch.float).sum().item()\n","    loss = loss_fn(pred, labels)\n","    return correct, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOsATrHB2-ML","executionInfo":{"status":"aborted","timestamp":1678365252518,"user_tz":-180,"elapsed":16,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}}},"outputs":[],"source":["def train_single_epoch(model: torch.nn.Module,\n","                       optimizer: torch.optim.Optimizer, \n","                       loss_function: torch.nn.Module, \n","                       datagiver,\n","                       train_data_processing,\n","                       scheduler,\n","                       epoch_number,\n","                       scheduler_step_every_epoch = False):\n","    steps_per_epoch = datagiver.get_train_steps_per_epoch()\n","\n","    model.train()\n","    loss_val = 0\n","    with tqdm(total=steps_per_epoch) as pbar:\n","        for step in range(steps_per_epoch):\n","            data = datagiver.get(block=True)\n","            loss = train_data_processing(data, model, loss_function)\n","            loss_val += loss.item()\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if scheduler_step_every_epoch:\n","                scheduler.step(epoch_number + step / steps_per_epoch)\n","            \n","            pbar.update()\n","            pbar.set_postfix({'loss_value - ': loss_val, 'loss on batch - ': loss.item()})\n","            \n","    if not scheduler_step_every_epoch:\n","        scheduler.step()\n","    clear_cuda()\n","    loss_val /= steps_per_epoch\n","    return loss_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmxpQL1N8Znq","executionInfo":{"status":"aborted","timestamp":1678365252519,"user_tz":-180,"elapsed":17,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}}},"outputs":[],"source":["def validate_single_epoch(model: torch.nn.Module,\n","                          loss_function: torch.nn.Module, \n","                          datagiver,\n","                          val_data_processing):\n","    model.eval()\n","    steps_per_epoch = datagiver.get_val_steps_per_epoch()\n","    batch_size = datagiver.get_val_batch_size()\n","\n","    size = steps_per_epoch * batch_size\n","    val_loss, correct = 0, 0\n","    \n","    with torch.no_grad():\n","        for _ in range(steps_per_epoch):\n","            data = datagiver.get(block=True)\n","            step_correct, step_val_loss = val_data_processing(data, model, loss_function)\n","            \n","            correct += step_correct\n","            val_loss += step_val_loss\n","\n","    clear_cuda()\n","            \n","    val_loss /= steps_per_epoch\n","    correct /= size\n","    print('accuracy - {} , loss - {}'.format(correct, val_loss))\n","    return {'loss': val_loss, 'accuracy' : correct}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VqF21yYr87HP","executionInfo":{"status":"aborted","timestamp":1678365252522,"user_tz":-180,"elapsed":20,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}}},"outputs":[],"source":["def train_model(model: torch.nn.Module, \n","                datagiver,\n","                path_to_save,\n","                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n","                optimizer_params = 'default',\n","                lr_scheduler_class = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n","                lr_scheduler_params: Dict = {},\n","                lr_scheduler_step_every_epoch = False,\n","                max_epochs = 50,\n","                early_stopping_patience = 15,\n","                loss_progression = None,\n","                train_data_processing = train_data_processing_celeba,\n","                val_data_processing = val_data_processing_celeba,\n","                model_name_appendix=\"\"):\n","    if optimizer_params == 'default':\n","        optimizer = adabelief_pytorch.AdaBelief(model.parameters(),\n","                                                lr=0.01,\n","                                                betas=(0.9, 0.999),\n","                                                eps=1e-8,\n","                                                weight_decouple=True,\n","                                                rectify=False,\n","                                                weight_decay=1e-2,\n","                                                fixed_decay=False,\n","                                                amsgrad=False)\n","    else:\n","        optimizer = adabelief_pytorch.AdaBelief(model.parameters(), **optimizer_params)\n","        \n","    scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n","\n","    best_val_loss = None\n","    best_epoch = None\n","    \n","    loss_history = []\n","    \n","    with tqdm(total=max_epochs) as pbar:\n","        for epoch in tqdm(range(max_epochs)):\n","            datagiver.change_task('train')\n","            train_epoch_loss_history = train_single_epoch(model,\n","                                                          optimizer,\n","                                                          loss_function,\n","                                                          datagiver,\n","                                                          train_data_processing,\n","                                                          scheduler,\n","                                                          epoch,\n","                                                          scheduler_step_every_epoch = lr_scheduler_step_every_epoch)\n","            \n","            loss_history.append(train_epoch_loss_history)\n","            datagiver.change_task('validate')\n","            val_metrics = validate_single_epoch(model, loss_function, datagiver, val_data_processing)\n","            pbar.update\n","            pbar.set_postfix({'Epoch - ': epoch})\n","\n","            if loss_progression:\n","                loss_progression(loss_function)\n","            \n","            if best_val_loss is None or best_val_loss > val_metrics['loss']:\n","                print(f'Best model yet, saving')\n","                best_val_loss = val_metrics['loss']\n","                best_epoch = epoch\n","                torch.save(model, path_to_save + \"/\" + model.__class__.__name__ + '_best' + model_name_appendix + '.tp')\n","                \n","            if epoch - best_epoch > early_stopping_patience:\n","                print('Early stopping has been triggered')\n","                return\n","    return loss_history"]},{"cell_type":"code","source":[],"metadata":{"id":"fjcNXDNZXRPp","executionInfo":{"status":"aborted","timestamp":1678365252523,"user_tz":-180,"elapsed":21,"user":{"displayName":"Nikita Ushakov","userId":"10694674250451986039"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}