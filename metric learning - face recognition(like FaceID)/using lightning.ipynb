{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a229da-9bd9-4096-a5ac-c240271533e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn import ReLU, Conv2d, BatchNorm2d, Sequential, AdaptiveAvgPool2d, Linear, MaxPool2d, Flatten, CrossEntropyLoss\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except:\n",
    "    !pip install pytorch-lightning\n",
    "    import pytorch_lightning as pl\n",
    "try:\n",
    "    import adabelief_pytorch\n",
    "except:\n",
    "    !pip install adabelief_pytorch==0.2.0\n",
    "    time.sleep(1)\n",
    "    import adabelief_pytorch\n",
    "try:\n",
    "    from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "except:\n",
    "    !pip install pytorch_metric_learning\n",
    "    time.sleep(1)\n",
    "    from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e66529f-376e-40bb-ba66-f762615fd15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1b17d4-00da-4dc7-8948-f3783fefd329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 21 16:58:27 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 517.48       Driver Version: 517.48       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   34C    P2    25W / 200W |    622MiB /  3072MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1128    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2224    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      8692    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10908    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11016    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     11252    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c98bdc5-7025-4e5d-8f53-0a238f109779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim = 128):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.__embedding_dim = embedding_dim\n",
    "        self.__build_resnet()\n",
    "        \n",
    "    def __build_resnet(self):\n",
    "        self.__inner = torchvision.models.resnet18(weights = torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "        self.__inner.fc = Linear(512, self.__embedding_dim)\n",
    "        \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self.__embedding_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.__inner(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3f9a46-354b-4ae8-8ce0-7037dfecc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        anchor, positive, negative = batch[0][0], batch[1][0], batch[2][0]\n",
    "        dist_ap = torch.linalg.nor(anchor - positive, dim=1)\n",
    "        dist_an = torch.linalg.nor(anchor - negative, dim=1)\n",
    "        loss = torch.clamp(dist_ap - dist_an + self.margin, min=0)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2efe7df-f759-4ffd-9af0-a2c45d8303a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalClassifier(torch.nn.Linear):\n",
    "    def __CosFace(scale, margin):\n",
    "        def wrapped_loss(cosines, target):\n",
    "            one_hot = torch.zeros_like(cosines)\n",
    "            one_hot.scatter_(1, target.view(-1, 1).long(), 1)\n",
    "            logits = scale * (cosines - margin * one_hot)\n",
    "            return logist\n",
    "        return wrapped_loss\n",
    "    \n",
    "    def __SphereFace(scale, margin):\n",
    "        def wrapper_loss(cosines, target):\n",
    "            one_hot = torch.zeros_like(cosines)\n",
    "            one_hot.scatter_(1, target.view(-1, 1).long(), 1)\n",
    "            \n",
    "            req_cosines = one_hot * cosines\n",
    "            req_cosines = torch.sum(req_cosines, dim=1, keepdim=True)\n",
    "            req_cosines = torch.cos(margin * torch.arccos(req_cosines))\n",
    "            logits = scale * cosines.scatter(dim=1,\n",
    "                                             index=target.view(-1, 1).long(),\n",
    "                                             src=req_cosines)\n",
    "            return logits\n",
    "        return wrapped_loss\n",
    "    \n",
    "    def __ArcFace(scale, margin):\n",
    "        def wrapped_loss(cosines, target):\n",
    "            one_hot = torch.zeros_like(cosines)\n",
    "            one_hot.scatter_(1, target.view(-1, 1).long(), 1)\n",
    "            \n",
    "            req_cosines = one_hot * cosines\n",
    "            req_cosines = torch.sum(req_cosines, dim=1, keepdim=True)\n",
    "            req_cosines = torch.cos(margin + torch.arccos(req_cosines))\n",
    "            logits = scale * cosines.scatter(dim=1,\n",
    "                                             index=target.view(-1, 1).long(),\n",
    "                                             src=req_cosines)\n",
    "            return logits\n",
    "        return wrapped_loss\n",
    "    \n",
    "    __margin_types = {'CosFace' : __CosFace,\n",
    "                      'SphereFace' : __SphereFace,\n",
    "                      'ArcFace' : __ArcFace}\n",
    "    \n",
    "    def __init__(self, in_features, out_features, scale = 64, margin=0.35, margin_type = 'CosFace'):\n",
    "        super(SphericalClassifier, self).__init__(in_features, out_features, bias=False)\n",
    "        self._scale = scale\n",
    "        self._margin = margin\n",
    "        self._margin_type = margin_type\n",
    "        \n",
    "        self._modified_softmax = self.__make_margin_loss()\n",
    "        \n",
    "    def __make_margin_loss(self):\n",
    "        if not self._margin_type in SphericalClassifier.__margin_types:\n",
    "            raise ValueError('There is no such type - {}'.format(self._margin_type))\n",
    "        else:\n",
    "            return SphericalClassifier.__margin_types[self._margin_type](self._scale, self._margin)\n",
    "        \n",
    "    def forward(self, data, target):\n",
    "        cosines = torch.nn.functional.linear(torch.nn.functional.normalize(data),\n",
    "                                  torch.nn.functional.normalize(self.weight))\n",
    "        logits = self._modified_softmax(cosines, target)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94465889-0f00-48f1-8367-15c65161dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITERIONS = {'CE' : torch.nn.CrossEntropyLoss,\n",
    "            'TripletLoss' : TripletLoss}\n",
    "\n",
    "CLASSIFIERS = {'linear' : torch.nn.Linear,\n",
    "              'SphericalClassifier' : SphericalClassifier}\n",
    "\n",
    "config = {\n",
    "    'embedding_dim' : 64,\n",
    "    'scheduler' : {\n",
    "        'type' : torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "        'step_every_batch' : True,\n",
    "        'params' : {\n",
    "            'eta_min' : 2e-4,\n",
    "            'T_0' : 1\n",
    "        }\n",
    "    },\n",
    "    'optimization' : {\n",
    "        'optimizer' : adabelief_pytorch.AdaBelief,\n",
    "        'params' : {\n",
    "            'lr' : 1e-3,\n",
    "            'betas' : (0.9, 0.999),\n",
    "            'eps' : 1e-8,\n",
    "            'weight_decay' : 5e-4,\n",
    "            'weight_decouple' : False,\n",
    "            'rectify' : False,\n",
    "            'fixed_decay' : False,\n",
    "            'amsgrad' : False\n",
    "        }\n",
    "    },\n",
    "    'dataset_params' : {\n",
    "        'batch_size' : 256\n",
    "    },\n",
    "    'criterion' : {\n",
    "        'type' : 'CE',\n",
    "        'params' : {}\n",
    "    },\n",
    "    'classifier': {\n",
    "        'type' : 'SphericalClassifier',\n",
    "        'params' : {\n",
    "            'scale' : 64,\n",
    "            'margin' : 0.35,\n",
    "            'margin_type' : 'CosFace'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0751e2-7f08-455b-b0f6-a7c670fb81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Module(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self._config = config\n",
    "        self.embedder = Embedder(config['embedding_dim'])\n",
    "        self.classifier = self.get_classifier()\n",
    "        self.criterion = self.get_criterion()\n",
    "        self.recall_calculator = AccuracyCalculator(\n",
    "            include=(\"precision_at_1\", \"mean_average_precision_at_r\"), k=\"max_bin_count\"\n",
    "        )\n",
    "  \n",
    "    def train_dataset(self):\n",
    "        transform = torchvision.transforms.Compose(\n",
    "            [torchvision.transforms.AutoAugment(torchvision.transforms.AutoAugmentPolicy.CIFAR10),\n",
    "            torchvision.transforms.ToTensor()]\n",
    "        )\n",
    "        CIFAR_trainset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', train=True, download=True, transform=transform\n",
    "        )\n",
    "        return CIFAR_trainset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self.train_dataset()\n",
    "        params = self._config[\"dataset_params\"]\n",
    "        if \"use_balanced_sampler\" in params and params[\"use_balanced_sampler\"]:\n",
    "            sampler = ShuffledClassBalancedBatchSampler(\n",
    "                dataset, params[\"batch_size\"], params[\"samples_per_class\"]\n",
    "            )\n",
    "            return torch.utils.data.DataLoader(\n",
    "                dataset, batch_sampler=sampler\n",
    "            )\n",
    "        else:\n",
    "            return torch.utils.data.DataLoader(\n",
    "                dataset, params[\"batch_size\"], shuffle=True, num_workers=4\n",
    "            )\n",
    "    \n",
    "    def test_dataset(self):\n",
    "        CIFAR_testset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', train=False, download=True,\n",
    "            transform=torchvision.transforms.ToTensor()\n",
    "        )\n",
    "        return CIFAR_testset\n",
    "  \n",
    "    def test_dataloader(self):\n",
    "        dataset = self.test_dataset()\n",
    "        params = self._config[\"dataset_params\"]\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset, batch_size = params[\"batch_size\"], num_workers=4\n",
    "        )\n",
    "  \n",
    "    def val_dataloader(self):\n",
    "        return self.test_dataloader()\n",
    "  \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_params = self._config[\"optimization\"]['params']\n",
    "        optimizer_class = self._config['optimization']['optimizer']\n",
    "        optimizer = optimizer_class(self.parameters(), **optimizer_params)\n",
    "        \n",
    "        scheduler_class = self._config[\"scheduler\"]['type']\n",
    "        scheduler_params = self._config[\"scheduler\"]['params']\n",
    "        scheduler = {\n",
    "            'scheduler' : scheduler_class(optimizer, **scheduler_params),\n",
    "            'interval' : 'step' if self._config['scheduler']['step_every_batch'] else 'epoch'\n",
    "        }\n",
    "        return {'optimizer' : optimizer,\n",
    "                'lr_scheduler' : scheduler}\n",
    "    \n",
    "    def get_criterion(self):\n",
    "        criterion_type = self._config[\"criterion\"]['type']\n",
    "        params = self._config['criterion'][\"params\"]\n",
    "        return CRITERIONS[criterion_type](**params)\n",
    "    \n",
    "    def get_classifier(self):\n",
    "        classifier_type = self._config['classifier'][\"type\"]\n",
    "        params = self._config['classifier'][\"params\"]\n",
    "        return CLASSIFIERS[classifier_type](self._config['embedding_dim'], 10, **params)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        embeddings = self.embedder(images)\n",
    "        if isinstance(self.criterion, torch.nn.CrossEntropyLoss):\n",
    "            if isinstance(self.classifier, SphericalClassifier):\n",
    "                logits = self.classifier(embeddings, labels)\n",
    "            else:\n",
    "                logits = self.classifier(embeddings)\n",
    "            loss = self.criterion(logits, labels)\n",
    "        elif isinstance(self.criterion, TriptetLoss):\n",
    "            triplets = generate_triplets((embeddings, labels))\n",
    "            loss = self.criterion(triplets)\n",
    "        self.log(\"loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        embeddings = self.embedder(images)\n",
    "        return {\"embeddings\": embeddings.cpu(), \"labels\": labels.cpu()}\n",
    "    \n",
    "    def test_epoch_end(self, outputs) -> None:\n",
    "        embeddings = np.vstack([b[\"embeddings\"].numpy() for b in outputs])\n",
    "        labels = np.hstack([b[\"labels\"].numpy() for b in outputs])\n",
    "        if embeddings.shape[1] == 3:\n",
    "            embeddings = embeddings / np.sqrt((embeddings ** 2).sum(-1))[..., np.newaxis]\n",
    "        metrics = self.recall_calculator.get_accuracy(\n",
    "            embeddings, labels,\n",
    "            embeddings, labels\n",
    "        )\n",
    "        self.log(\"r_at_one\", metrics[\"precision_at_1\"])\n",
    "        self.log(\"map_at_r\", metrics[\"mean_average_precision_at_r\"])\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.test_step(batch, batch_idx)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs) -> None:\n",
    "        embeddings = np.vstack([b[\"embeddings\"].numpy() for b in outputs])\n",
    "        labels = np.hstack([b[\"labels\"].numpy() for b in outputs])\n",
    "        print(embeddings.shape)\n",
    "        print(labels.shape)\n",
    "        metrics = self.recall_calculator.get_accuracy(\n",
    "            embeddings, labels,\n",
    "            embeddings, labels\n",
    "        )\n",
    "        self.log(\"val_r_at_one\", metrics[\"precision_at_1\"])\n",
    "        self.log(\"val_map_at_r\", metrics[\"mean_average_precision_at_r\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b49e79-5dfc-469c-aa94-efe27965f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = CIFAR10Module(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8cedfe-67a5-41a4-b62d-c0668b66957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | embedder   | Embedder            | 11.2 M\n",
      "1 | classifier | SphericalClassifier | 640   \n",
      "2 | criterion  | CrossEntropyLoss    | 0     \n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.840    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334a1485a5424563b067277ceaab38b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\"./logs\", name='ce')\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    max_epochs=20\n",
    ")\n",
    "trainer.fit(module)\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd16988-cef6-49ab-be7e-4e29b7a18190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
