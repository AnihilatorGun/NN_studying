{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"smy1IHEJijF6"},"outputs":[],"source":["import numpy as np  # Load required libs\n","import pandas as pd\n","import torch\n","import torchvision\n","from typing import Tuple, List, Type, Dict, Any\n","from sklearn.utils import shuffle\n","from torch.autograd import Variable\n","from threading import Thread, Lock\n","import os\n","import pickle\n","import datetime\n","import gzip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e87f42WCircg"},"outputs":[],"source":["class Threadsafe_iter:\n","    \"\"\"\n","    Takes an iterator/generator and makes it thread-safe by\n","    serializing call to the `next` method of given iterator/generator.\n","    You have to use it in a such way - Threadsafe_iter(get_objects_i(len(#your_unsafe_list)))\n","    \"\"\"\n","    def __init__(self, it):\n","        self.it = it\n","        self.lock = Lock()\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        with self.lock:\n","            return next(self.it)\n","\n","def get_objects_i(objects_count):\n","    \"\"\"Cyclic generator of paths indices\"\"\"\n","    current_objects_id = 0\n","    while True:\n","        yield current_objects_id\n","        current_objects_id  = (current_objects_id + 1) % objects_count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONXv2LwVCQNj"},"outputs":[],"source":["class CelebADataset:\n","    def __init__(self, id_path_correspondence, transform=None):\n","        self.__id_path_correspondence = id_path_correspondence\n","        self.__transform = transform\n","\n","    def __len__(self):\n","        return len(self.__id_path_correspondence)\n","\n","    def __getitem__(self, idx):\n","        path, label = self.__id_path_correspondence[idx]\n","        img = torchvision.io.read_image(path, mode = torchvision.io.ImageReadMode.RGB)\n","        if self.__transform:\n","            img = self.__transform(img)\n","        return img, label    \n","\n","    def make_train_test_datasets(zip_path=\"drive/MyDrive/GitHub/NN studying/NN_studying/metric learning - face recognition(like FaceID)/data/img_align_celeba.zip\",\n","                                 annotation_path = \"drive/MyDrive/GitHub/NN studying/NN_studying/metric learning - face recognition(like FaceID)/data/identity_CelebA.txt\",\n","                                 extract_path=\"\",\n","                                 transform_train=None,\n","                                 transform_test=None,\n","                                 train_test_ratio=0.8,\n","                                 seed=42,\n","                                 min_num_imgs_in_class=10):\n","        if not extract_path == \"\":\n","            if extract_path[-1] != \"/\":\n","                extract_path += \"/\"\n","\n","        if not os.path.exists(extract_path):\n","            data_zip = zipfile.ZipFile(zip_path)\n","            data_zip.extractall(extract_path)\n","            data_zip.close() \n","        \n","        extract_path += \"img_align_celeba/\"\n","\n","        id_path_correspondence = {}\n","        with open(annotation_path) as f:\n","            for line in f:\n","                path, id = line.split('\\n')[0].split(' ')\n","                id = int(id)\n","                if id in id_path_correspondence:\n","                    id_path_correspondence[id].append(extract_path + path)\n","                else:\n","                    id_path_correspondence[id] = [extract_path + path,]\n","\n","        ids_to_delete = []\n","        for id, pathes in id_path_correspondence.items():\n","            if len(pathes) < min_num_imgs_in_class:\n","                ids_to_delete.append(id)\n","        for id_to_delete in ids_to_delete:\n","            id_path_correspondence.pop(id_to_delete)\n","\n","        id_path_correspondence_clear = {}\n","        for i, (init_id, pathes) in enumerate(id_path_correspondence.items()):\n","            id_path_correspondence_clear[i] = pathes\n","\n","        id_path_correspondence_train = []\n","        id_path_correspondence_test = []\n","        np.random.seed(seed)\n","        num_classes = 0\n","        for id, pathes in id_path_correspondence_clear.items():\n","            num_classes += 1\n","            mask = np.linspace(0, 1, len(pathes)) < train_test_ratio\n","            np.random.shuffle(mask)\n","            id_path_correspondence_train += list((path, id) for path, mask_i in zip(pathes, mask) if mask_i)\n","            id_path_correspondence_test += list((path, id) for path, mask_i in zip(pathes, mask) if not mask_i)\n","        print(\"num_classes - {}\".format(num_classes))\n","\n","        return CelebADataset(id_path_correspondence_train, transform_train), CelebADataset(id_path_correspondence_test, transform_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jelQZn_vCQNk"},"outputs":[],"source":["class FlexDataloader:\n","    def __init__(self,\n","                 batch_size: int,\n","                 dataset):\n","        self.__batch_size = batch_size\n","        self.__dataset = dataset\n","        \n","        self._yield_lock = Lock()\n","        self._lock = Lock()\n","        self.__make_indices_and_safe_iter()\n","        \n","    def __make_indices_and_safe_iter(self):\n","        self.__dataset_indices = np.arange(len(self.__dataset))\n","        self.__safe_iter = Threadsafe_iter(get_objects_i(len(self.__dataset)))\n","\n","        self.__yielded_batches = 0\n","        self.__num_batches_in_epoch = self.get_steps_per_epoch()\n","                \n","    def shuffle(self):\n","        self.__dataset_indices = shuffle(self.__dataset_indices)\n","        \n","    def __len__(self):\n","        return len(self.__dataset_indices)\n","    \n","    def __iter__(self):\n","        with self._lock:\n","            self.shuffle()\n","            self.batch = []\n","        while True:\n","            for pre_ID in self.__safe_iter:\n","                ID = self.__dataset_indices[pre_ID]\n","                data = self.__dataset[ID]\n","                \n","                with self._yield_lock:\n","                    if len(self.batch) < self.__batch_size:\n","                        self.batch.append(data)\n","                    if len(self.batch) % self.__batch_size == 0:\n","                        yield self.batch\n","                        self.batch = []\n","                        self.__yielded_batches += 1\n","                        if self.__yielded_batches > self.__num_batches_in_epoch:\n","                            self.shuffle()\n","                            self.__yielded_batches = 0\n","                        \n","    def get_steps_per_epoch(self):\n","        return len(self) // self.get_batch_size() + 1\n","    \n","    def get_batch_size(self):\n","        return self.__batch_size"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}