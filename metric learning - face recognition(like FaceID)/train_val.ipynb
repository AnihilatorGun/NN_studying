{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGeRrOhu2rXX"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Load required libs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import zipfile\n",
    "import copy\n",
    "import time\n",
    "import sys\n",
    "from typing import Tuple, List, Type, Dict, Any\n",
    "import adabelief_pytorch\n",
    "import gc  # sometimes it is required to clean GPU memory in that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aQRIWg_7pYx"
   },
   "outputs": [],
   "source": [
    "def clear_cuda():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aNNeXlRB9ou"
   },
   "outputs": [],
   "source": [
    "def train_data_processing_casia(data, model, loss_function):\n",
    "    anchor = data[0]\n",
    "    positive = data[1]\n",
    "    target = data[2]\n",
    "\n",
    "    anchor_pred, anchor_embedding = model(anchor)\n",
    "    positive_pred, positive_embedding = model(positive)\n",
    "    return loss_function(anchor_pred, anchor_embedding, positive_pred, positive_embedding, target)\n",
    "\n",
    "def train_data_processing_cifar(data, model, loss_function):\n",
    "    img = data[0]\n",
    "    target = data[1]\n",
    "\n",
    "    pred = model(img)\n",
    "    return loss_function(pred, target)\n",
    "\n",
    "def val_data_processing_casia(data, model, loss_function):\n",
    "    anchor = data[0]\n",
    "    target = data[1]\n",
    "    anchor_pred, anchor_embedding = model(anchor)\n",
    "    \n",
    "    correct = (anchor_pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "    val_loss = loss_function(anchor_pred, target).item()\n",
    "    return correct, val_loss\n",
    "\n",
    "def val_data_processing_cifar(data, model, loss_function):\n",
    "    img = data[0]\n",
    "    target = data[1]\n",
    "    pred = model(img)\n",
    "\n",
    "    correct = (pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "    val_loss = loss_function(pred, target).item()\n",
    "    return correct, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOsATrHB2-ML"
   },
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer, \n",
    "                       loss_function: torch.nn.Module, \n",
    "                       datagiver,\n",
    "                       data_processing):\n",
    "    steps_per_epoch = datagiver.get_train_steps_per_epoch()\n",
    "    batch_size = datagiver.get_train_batch_size()\n",
    "\n",
    "    model.train()\n",
    "    size = steps_per_epoch * batch_size # STEPS_PER_EPOCH_TRAIN * BATCH_SIZE\n",
    "    loss_val = 0\n",
    "    with tqdm(total=steps_per_epoch) as pbar:\n",
    "        step = 0\n",
    "        for _ in range(steps_per_epoch):\n",
    "            data = datagiver.get(block=True)\n",
    "            loss = data_processing(data, model, loss_function)\n",
    "            loss_val += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "            pbar.set_postfix({'Batch num - ': step, 'loss_value - ': loss_val, 'loss on batch - ': loss.item()})\n",
    "            step += 1\n",
    "    clear_cuda()\n",
    "    loss_val = loss_val / size\n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmxpQL1N8Znq"
   },
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          datagiver,\n",
    "                          data_processing):\n",
    "    model.eval()\n",
    "    steps_per_epoch = datagiver.get_val_steps_per_epoch()\n",
    "    batch_size = datagiver.get_val_batch_size()\n",
    "\n",
    "    size = steps_per_epoch * batch_size\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps_per_epoch):\n",
    "            data = datagiver.get(block=True)\n",
    "            d_correct, d_val_loss = data_processing(data, model, loss_function)\n",
    "            \n",
    "            correct += d_correct\n",
    "            val_loss += d_val_loss\n",
    "\n",
    "    clear_cuda()\n",
    "            \n",
    "    val_loss /= steps_per_epoch\n",
    "    correct /= size\n",
    "    print('correct - {} , loss - {}'.format(correct, val_loss))\n",
    "    return {'loss': val_loss, 'accuracy' : correct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqF21yYr87HP"
   },
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, \n",
    "                datagiver,\n",
    "                path_to_save,\n",
    "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "                optimizer_params = 'default',\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                max_epochs = 50,\n",
    "                early_stopping_patience = 15,\n",
    "                save_each_epoch=False,\n",
    "                loss_progression = None,\n",
    "                dataset_name = 'cifar'):\n",
    "    train_processing = {'cifar':train_data_processing_cifar, 'casia':train_data_processing_casia}\n",
    "    val_processing = {'cifar':val_data_processing_cifar, 'casia':val_data_processing_casia}\n",
    "    \n",
    "    if optimizer_params == 'default':\n",
    "        optimizer = adabelief_pytorch.AdaBelief(model.parameters(),\n",
    "                                                lr=0.01,\n",
    "                                                betas=(0.9, 0.999),\n",
    "                                                eps=1e-8,\n",
    "                                                weight_decouple=True,\n",
    "                                                rectify=False,\n",
    "                                                weight_decay=1e-2,\n",
    "                                                fixed_decay=False,\n",
    "                                                amsgrad=False)\n",
    "    else:\n",
    "        optimizer = adabelief_pytorch.AdaBelief(model.parameters(), **optimizer_params)\n",
    "    \n",
    "    lr_scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)  # Расписание\n",
    "    lr_scheduler2 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.965)\n",
    "\n",
    "    if dataset_name == 'casia':\n",
    "        val_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        val_loss_fn = loss_function\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    with tqdm(total=max_epochs) as pbar:\n",
    "        for epoch in tqdm(range(max_epochs)):\n",
    "            datagiver.change_task('train')\n",
    "            train_epoch_loss_history = train_single_epoch(model, optimizer, loss_function, datagiver, train_processing[dataset_name])\n",
    "            loss_history.append(train_epoch_loss_history)\n",
    "            datagiver.change_task('validate')\n",
    "            val_metrics = validate_single_epoch(model, val_loss_fn, datagiver, val_processing[dataset_name])\n",
    "            lr_scheduler1.step(val_metrics['loss'])\n",
    "            lr_scheduler2.step()\n",
    "            pbar.update\n",
    "            pbar.set_postfix({'Epoch - ': epoch})\n",
    "\n",
    "            if loss_progression:\n",
    "                loss_progression(loss_function)\n",
    "            \n",
    "            if best_val_loss is None or best_val_loss > val_metrics['loss']:\n",
    "                print(f'Best model yet, saving')\n",
    "                best_val_loss = val_metrics['loss']\n",
    "                best_epoch = epoch\n",
    "                torch.save(model, path_to_save + model.__class__.__name__ + '_best' + '.tp')\n",
    "                \n",
    "            if epoch - best_epoch > early_stopping_patience:\n",
    "                print('Early stopping has been triggered')\n",
    "                return\n",
    "    return loss_history"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaRTwC/V1LGi8LOQxcED0H",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
