{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOaRTwC/V1LGi8LOQxcED0H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LGeRrOhu2rXX"},"outputs":[],"source":["import numpy as np  # Load required libs\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","from tqdm.notebook import tqdm\n","import os\n","import zipfile\n","import copy\n","import time\n","import sys\n","from typing import Tuple, List, Type, Dict, Any\n","import adabelief_pytorch\n","import gc  # sometimes it is required to clean GPU memory in that way"]},{"cell_type":"code","source":["def clear_cuda():\n","    gc.collect()\n","    torch.cuda.empty_cache()"],"metadata":{"id":"2aQRIWg_7pYx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_data_processing_casia(data, model, loss_function):\n","    anchor = data[0]\n","    positive = data[1]\n","    target = data[2]\n","\n","    anchor_pred, anchor_embedding = model(anchor)\n","    positive_pred, positive_embedding = model(positive)\n","    return loss_function(anchor_pred, anchor_embedding, positive_pred, positive_embedding, target)\n","\n","def train_data_processing_cifar(data, model, loss_function):\n","    img = data[0]\n","    target = data[1]\n","\n","    pred = model(img)\n","    return loss_function(pred, target)\n","\n","def val_data_processing_casia(data, model, loss_function):\n","    anchor = data[0]\n","    target = data[1]\n","    anchor_pred, anchor_embedding = model(anchor)\n","    \n","    correct = (anchor_pred.argmax(1) == target).type(torch.float).sum().item()\n","    val_loss = loss_function(anchor_pred, target).item()\n","    return correct, val_loss\n","\n","def val_data_processing_cifar(data, model, loss_function):\n","    img = data[0]\n","    target = data[1]\n","    pred = model(img)\n","\n","    correct = (pred.argmax(1) == target).type(torch.float).sum().item()\n","    val_loss = loss_function(pred, target).item()\n","    return correct, val_loss"],"metadata":{"id":"1aNNeXlRB9ou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_single_epoch(model: torch.nn.Module,\n","                       optimizer: torch.optim.Optimizer, \n","                       loss_function: torch.nn.Module, \n","                       datagiver,\n","                       data_processing):\n","    steps_per_epoch = datagiver.get_train_steps_per_epoch()\n","    batch_size = datagiver.get_train_batch_size()\n","\n","    model.train()\n","    size = steps_per_epoch * batch_size # STEPS_PER_EPOCH_TRAIN * BATCH_SIZE\n","    loss_val = 0\n","    with tqdm(total=steps_per_epoch) as pbar:\n","        step = 0\n","        for _ in range(steps_per_epoch):\n","            data = datagiver.get(block=True)\n","            loss = data_processing(data, model, loss_function)\n","            loss_val += loss.item()\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            pbar.update()\n","            pbar.set_postfix({'Batch num - ': step, 'loss_value - ': loss_val, 'loss on batch - ': loss.item()})\n","            step += 1\n","    clear_cuda()\n","    loss_val = loss_val / size\n","    return loss_val"],"metadata":{"id":"sOsATrHB2-ML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate_single_epoch(model: torch.nn.Module,\n","                          loss_function: torch.nn.Module, \n","                          datagiver,\n","                          data_processing):\n","    model.eval()\n","    steps_per_epoch = datagiver.get_val_steps_per_epoch()\n","    batch_size = datagiver.get_val_batch_size()\n","\n","    size = steps_per_epoch * batch_size\n","    val_loss, correct = 0, 0\n","    \n","    with torch.no_grad():\n","        for _ in range(steps_per_epoch):\n","            data = datagiver.get(block=True)\n","            d_correct, d_val_loss = data_processing(data, model, loss_function)\n","            \n","            correct += d_correct\n","            val_loss += d_val_loss\n","\n","    clear_cuda()\n","            \n","    val_loss /= steps_per_epoch\n","    correct /= size\n","    print('correct - {} , loss - {}'.format(correct, val_loss))\n","    return {'loss': val_loss, 'accuracy' : correct}"],"metadata":{"id":"cmxpQL1N8Znq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model: torch.nn.Module, \n","                datagiver,\n","                path_to_save,\n","                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n","                optimizer_params = 'default',\n","                lr_scheduler_params: Dict = {},\n","                max_epochs = 50,\n","                early_stopping_patience = 15,\n","                save_each_epoch=False,\n","                loss_progression = None,\n","                dataset_name = 'cifar'):\n","    train_processing = {'cifar':train_data_processing_cifar, 'casia':train_data_processing_casia}\n","    val_processing = {'cifar':val_data_processing_cifar, 'casia':val_data_processing_casia}\n","    \n","    if optimizer_params == 'default':\n","        optimizer = adabelief_pytorch.AdaBelief(model.parameters(),\n","                                                lr=0.01,\n","                                                betas=(0.9, 0.999),\n","                                                eps=1e-8,\n","                                                weight_decouple=True,\n","                                                rectify=False,\n","                                                weight_decay=1e-2,\n","                                                fixed_decay=False,\n","                                                amsgrad=False)\n","    else:\n","        optimizer = adabelief_pytorch.AdaBelief(model.parameters(), **optimizer_params)\n","    \n","    lr_scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)  # Расписание\n","    lr_scheduler2 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.965)\n","\n","    if dataset_name == 'casia':\n","        val_loss_fn = torch.nn.CrossEntropyLoss()\n","    else:\n","        val_loss_fn = loss_function\n","\n","    best_val_loss = None\n","    best_epoch = None\n","    \n","    loss_history = []\n","    \n","    with tqdm(total=max_epochs) as pbar:\n","        for epoch in tqdm(range(max_epochs)):\n","            datagiver.change_task('train')\n","            train_epoch_loss_history = train_single_epoch(model, optimizer, loss_function, datagiver, train_processing[dataset_name])\n","            loss_history.append(train_epoch_loss_history)\n","            datagiver.change_task('validate')\n","            val_metrics = validate_single_epoch(model, val_loss_fn, datagiver, val_processing[dataset_name])\n","            lr_scheduler1.step(val_metrics['loss'])\n","            lr_scheduler2.step()\n","            pbar.update\n","            pbar.set_postfix({'Epoch - ': epoch})\n","\n","            if loss_progression:\n","                loss_progression(loss_function)\n","            \n","            if best_val_loss is None or best_val_loss > val_metrics['loss']:\n","                print(f'Best model yet, saving')\n","                best_val_loss = val_metrics['loss']\n","                best_epoch = epoch\n","                torch.save(model, path_to_save + model.__class__.__name__ + '_best' + '.tp')\n","                \n","            if epoch - best_epoch > early_stopping_patience:\n","                print('Early stopping has been triggered')\n","                return\n","    return loss_history"],"metadata":{"id":"VqF21yYr87HP"},"execution_count":null,"outputs":[]}]}