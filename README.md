# Hi! This repo represents my way of studying DeepLearning
____
## Resources that I use:
+ [Technotrack 2021](https://github.com/mailcourses/technotrack-NN2021S-lectures)
+ [HSE DeepLearning](https://github.com/hse-ds/iad-deep-learning/tree/master/2022)
+ [MIPT DeepLearningSchool](https://github.com/DLSchool/deep-learning-school)
+ [Tinkoff course](https://algocode.ru/dlfall22/)
+ [Dive into Deep Learning](http://d2l.ai/index.html)
+ [Other guides](https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide)
____
## Plans:
- [ ] Finish technotrack's lectures
- [ ] Make DeTR-like decoder for BERT encoder for multilable classification task
- [x] Look throught the Tinkoff's lectures
- [x] Refactor cloudiness estimation project
- [x] Learn how does Transformers work
- [x] Learn how does GAN work
- [x] CV trick (Squeeze&Excitation, DepthwiseSeparateConv and so on)
- [x] Autograd tricks
----
## Building blocks:
- [ ] Knoledge distillation, pruning
- [x] Transformers (BERT, DeTR)
- [x] GAN (MB StyleGAN2 left)
- [x] Metric learning (face recognition project)
____
## Pet projects:
- [ ] DeTR-like multilable classification (BERT as backbone)
- [ ] Cloudiness estimation (almost done, some minimal tests left)\
- [ ] FaceGeneration
- [x] Judging trampoline acrobatics (commertial one, there is video as a proof)
- [x] Face recognition